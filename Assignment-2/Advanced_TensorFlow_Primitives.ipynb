{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pytorch"
      ],
      "metadata": {
        "id": "gfotu3lUOgL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Matrix Transpose"
      ],
      "metadata": {
        "id": "2kugaF2IuIVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmjzlHmxqGP-",
        "outputId": "feb1e545-7a79-4aee-9e14-da1cc332451b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 3],\n",
              "        [1, 4],\n",
              "        [2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "a = torch.arange(6).reshape(2, 3)\n",
        "torch.einsum('ij->ji', [a])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Sum"
      ],
      "metadata": {
        "id": "3jkfnABfDcbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "torch.einsum('ij->', [a])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKWVZituB90z",
        "outputId": "5713ed76-632d-41d6-a04c-54fa71cd21c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Column Sum"
      ],
      "metadata": {
        "id": "GjOTQ11GDjMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "torch.einsum('ij->', [a])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt0KI5wrDeCp",
        "outputId": "7b72f8af-360a-416c-d825-c0824fe0d43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Row Sum"
      ],
      "metadata": {
        "id": "-6vtWaj3DoKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "torch.einsum('ij->i', [a])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl3Fohi9Dlac",
        "outputId": "735db656-674b-41f6-c479-b31b2c87c080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Matrix-Vector Multiplication"
      ],
      "metadata": {
        "id": "8tgzskZhDr9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "b = torch.arange(3)\n",
        "torch.einsum('ik,k->i', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbxfEPpqDpz_",
        "outputId": "238b6d69-b2e8-4ae0-ae8b-ed8f4bd32cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Matrix-Matrix Multiplication"
      ],
      "metadata": {
        "id": "q4KcVz7vD3yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "b = torch.arange(15).reshape(3, 5)\n",
        "torch.einsum('ik,kj->ij', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzIeXGosD19V",
        "outputId": "f9a961de-5bfb-44ff-ff27-bd7e0e92a154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 25,  28,  31,  34,  37],\n",
              "        [ 70,  82,  94, 106, 118]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dot Product"
      ],
      "metadata": {
        "id": "RUBwrwwcECFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(3)\n",
        "b = torch.arange(3,6)  # -- a vector of length 3 containing [3, 4, 5]\n",
        "torch.einsum('i,i->', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fYgSWPgD822",
        "outputId": "ff87578f-06a3-4302-9eb2-7c254e1c2017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "b = torch.arange(6,12).reshape(2, 3)\n",
        "torch.einsum('ij,ij->', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMrHxIIbEEb0",
        "outputId": "3b2a4e8b-8067-405c-a0d0-7c250125d044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(145)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Hadamard Product"
      ],
      "metadata": {
        "id": "_RkjNR7yEI2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6).reshape(2, 3)\n",
        "b = torch.arange(6,12).reshape(2, 3)\n",
        "torch.einsum('ij,ij->ij', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljMV2K-NEG5D",
        "outputId": "2ac74e48-6746-43ca-ca72-06aee66111e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  7, 16],\n",
              "        [27, 40, 55]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Outer Product"
      ],
      "metadata": {
        "id": "oEXgjIXvENp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(3)\n",
        "b = torch.arange(3,7)  # -- a vector of length 4 containing [3, 4, 5, 6]\n",
        "torch.einsum('i,j->ij', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh0L7KB2EMOS",
        "outputId": "9733036e-14ec-49f0-a3e1-73ec03840b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0],\n",
              "        [ 3,  4,  5,  6],\n",
              "        [ 6,  8, 10, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 10 Batch Natrix Multiplication"
      ],
      "metadata": {
        "id": "McetVmY4EUiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(3,2,5)\n",
        "b = torch.randn(3,5,3)\n",
        "torch.einsum('ijk,ikl->ijl', [a, b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js1NyNUfESF0",
        "outputId": "68a0d49d-65f0-4e02-984e-4a238802a63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.7533,  0.9838,  4.2215],\n",
              "         [ 0.5251,  0.1514, -0.9903]],\n",
              "\n",
              "        [[ 0.0628, -0.2901,  1.8549],\n",
              "         [ 0.9902, -3.1785,  1.2734]],\n",
              "\n",
              "        [[ 2.3475,  1.3995,  1.6970],\n",
              "         [-1.0486,  3.2466, -1.6432]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tensor Contraction"
      ],
      "metadata": {
        "id": "rCRMJZ1qEdiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2,3,5,7)\n",
        "b = torch.randn(11,13,3,17,5)\n",
        "torch.einsum('pqrs,tuqvr->pstuv', [a, b]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCoFQR2lEaM2",
        "outputId": "ccb62f8b-d330-47b4-833e-d8d187050cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 7, 11, 13, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bilinear Transformation"
      ],
      "metadata": {
        "id": "0LdorilsEjnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2,3)\n",
        "b = torch.randn(5,3,7)\n",
        "c = torch.randn(2,7)\n",
        "torch.einsum('ik,jkl,il->ij', [a, b, c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyYI6iCrEftF",
        "outputId": "8b289342-d233-4551-d213-4e008295114d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0259,  0.2628,  1.3368, -0.1365, -1.9054],\n",
              "        [-1.5134, -0.3314,  1.1292, -2.1423, -3.4076]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TreeQN"
      ],
      "metadata": {
        "id": "Rs7J2yoEEpCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "\n",
        "# Parameters\n",
        "# -- [num_actions x hidden_dimension]\n",
        "b = random_tensors([5, 3], requires_grad=True)\n",
        "# -- [num_actions x hidden_dimension x hidden_dimension]\n",
        "W = random_tensors([5, 3, 3], requires_grad=True)\n",
        "\n",
        "def transition(zl):\n",
        "  # -- [batch_size x num_actions x hidden_dimension]\n",
        "  return zl.unsqueeze(1) + F.tanh(torch.einsum(\"bk,aki->bai\", [zl, W]) + b)\n",
        "\n",
        "# Sampled dummy inputs\n",
        "# -- [batch_size x hidden_dimension]\n",
        "zl = random_tensors([2, 3])\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYGFZfhNEnBf",
        "outputId": "c47b2dee-8df6-410b-c740-6b1020079a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.8000, -0.5737,  0.1176],\n",
              "         [ 1.7033, -0.4210,  1.1105],\n",
              "         [ 0.6457, -0.5479, -0.7458],\n",
              "         [ 1.6984, -0.3482, -0.2988],\n",
              "         [-0.1527,  0.5527, -0.7778]],\n",
              "\n",
              "        [[ 2.0870, -0.5688,  3.6612],\n",
              "         [ 0.0892, -0.5683,  3.6652],\n",
              "         [ 1.6787,  1.1324,  1.6687],\n",
              "         [ 0.7338, -0.5268,  1.6658],\n",
              "         [ 0.0891,  1.1683,  1.8213]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Attention"
      ],
      "metadata": {
        "id": "DkVk2MHvEvy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "# -- [hidden_dimension]\n",
        "bM, br, w = random_tensors([7], num=3, requires_grad=True)\n",
        "# -- [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "# Single application of attention mechanism \n",
        "def attention(Y, ht, rt1):\n",
        "  # -- [batch_size x hidden_dimension] \n",
        "  tmp = torch.einsum(\"ik,kl->il\", [ht, Wh]) + torch.einsum(\"ik,kl->il\", [rt1, Wr])\n",
        "  Mt = F.tanh(torch.einsum(\"ijk,kl->ijl\", [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  # -- [batch_size x sequence_length]\n",
        "  at = F.softmax(torch.einsum(\"ijk,k->ij\", [Mt, w])) \n",
        "  # -- [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum(\"ijk,ij->ik\", [Y, at]) + F.tanh(torch.einsum(\"ij,jk->ik\", [rt1, Wt]) + br)\n",
        "  # -- [batch_size x hidden_dimension], [batch_size x sequence_dimension]\n",
        "  return rt, at\n",
        "\n",
        "# Sampled dummy inputs\n",
        "# -- [batch_size x sequence_length x hidden_dimension]\n",
        "Y = random_tensors([3, 5, 7])\n",
        "# -- [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "at  # -- print attention weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5riKqoEEEtZL",
        "outputId": "148a9355-06ab-4864-f561-8b7ce9598421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-edce8c55a8e9>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = F.softmax(torch.einsum(\"ijk,k->ij\", [Mt, w]))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2675, 0.0320, 0.5607, 0.0846, 0.0553],\n",
              "        [0.0116, 0.2793, 0.0555, 0.3135, 0.3400],\n",
              "        [0.3251, 0.0042, 0.6138, 0.0404, 0.0165]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "  \n",
        "  \n",
        "ar1 = np.arange(9).reshape(3, 3)\n",
        "ar2 = np.arange(10, 19).reshape(3, 3)\n",
        "\n",
        "# Original Higher dimension\n",
        "print(ar1)\n",
        "  \n",
        "print(ar2)\n",
        "print(\"\")\n",
        "r = np.einsum(\"mk,kn\", ar1, ar2)\n",
        "  \n",
        "# Einsteinâ€™s summation convention of \n",
        "# the said arrays\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScpuTePZE0Ae",
        "outputId": "a8041001-46c6-46d0-e006-0efe5ac5746e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "[[10 11 12]\n",
            " [13 14 15]\n",
            " [16 17 18]]\n",
            "\n",
            "[[ 45  48  51]\n",
            " [162 174 186]\n",
            " [279 300 321]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Permutation of tensor\n",
        "X = torch.rand((2, 3))\n",
        "\n",
        "A = torch.einsum('ij->ji', X)\n",
        "torch.transpose(X, 0, 1)  # or X.T\n",
        "\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFVAeyWfHGwr",
        "outputId": "bd040af6-47e1-4b5f-eee2-3f84d69efb19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0124, 0.1227],\n",
            "        [0.8782, 0.1298],\n",
            "        [0.8623, 0.3020]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Summation\n",
        "X = torch.rand((2, 3))\n",
        "\n",
        "a = torch.einsum('ij->', X)\n",
        "torch.sum(X)\n",
        "\n",
        "print(a) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-cOGstwSXCm",
        "outputId": "4d840755-5d94-4f84-8aab-1694ca6ec49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.6155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "X = torch.rand((2, 3))\n",
        "\n",
        "# Row summation\n",
        "a = torch.einsum('ij->i', X)\n",
        "torch.sum(X, axis=1)\n",
        "\n",
        "print(a)  # tensor([1.4088, 1.7803])\n",
        "\n",
        "# Column summation\n",
        "b = torch.einsum('ij->j', X)\n",
        "torch.sum(X, axis=0)\n",
        "\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGdeux7USZyG",
        "outputId": "60521b18-431b-491a-da30-8da20c082a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2118, 1.5576])\n",
            "tensor([0.8242, 0.7641, 1.1811])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Element wise multiplication\n",
        "X = torch.rand((3, 2))\n",
        "Y = torch.rand((3, 2))\n",
        "\n",
        "A = torch.einsum('ij, ij->ij', X, Y)\n",
        "torch.mul(X, Y)  # or X * Y\n",
        "\n",
        "print(A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4xUokv4SjlC",
        "outputId": "a7b68ba8-b1f3-4518-dc4a-0572a3e604c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2857, 0.1730],\n",
            "        [0.1584, 0.3148],\n",
            "        [0.0921, 0.7806]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Dot product\n",
        "v = torch.rand((3))\n",
        "c = torch.rand((3))\n",
        "\n",
        "a = torch.einsum('i, i->', v, c)\n",
        "torch.dot(v, c)\n",
        "\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70JdBMUxSnLn",
        "outputId": "c9225b5c-211b-40fb-eee2-1ef6f96832d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4703)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Outer product\n",
        "v = torch.rand((3))\n",
        "t = torch.rand((3))\n",
        "\n",
        "A = torch.einsum('i, j->ij', v, t)\n",
        "torch.outer(v, t)\n",
        "\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5CMO6PfSrsR",
        "outputId": "1cee2d9f-4f96-4148-9350-ba13fc7f7064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5432, 0.3109, 0.0754],\n",
            "        [0.1587, 0.0908, 0.0220],\n",
            "        [0.5645, 0.3230, 0.0783]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Matrix-Vector multiplication\n",
        "X = torch.rand((3, 3))\n",
        "y = torch.rand((1, 3))\n",
        "\n",
        "A = torch.einsum('ij, kj->ik', X, y)\n",
        "torch.mm(X, torch.transpose(y, 0, 1))  # or torch.mm(X, y.T)\n",
        "\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytEdGtkZSubP",
        "outputId": "ac80ec34-39aa-4364-f7be-9cacbe9b045f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6994],\n",
            "        [0.6861],\n",
            "        [0.3227]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Matrix-Matrix multiplication\n",
        "X = torch.arange(6).reshape(2, 3)\n",
        "Y = torch.arange(12).reshape(3, 4)\n",
        "\n",
        "A = torch.einsum('ij, jk->ik', X, Y)\n",
        "torch.mm(X, Y)\n",
        "\n",
        "print(A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rnsYNK3SzGU",
        "outputId": "3f7a7a8f-9be2-4151-dc82-6216b9c9ee91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[20, 23, 26, 29],\n",
            "        [56, 68, 80, 92]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# Batch matrix multiplication\n",
        "X = torch.arange(24).reshape(2, 3, 4)\n",
        "Y = torch.arange(40).reshape(2, 4, 5)\n",
        "\n",
        "A = torch.einsum('ijk, ikl->ijl', X, Y)\n",
        "torch.bmm(X, Y)\n",
        "\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWsuGPnCS3As",
        "outputId": "ce990a41-96fc-47d7-a960-27ebc01a7622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  70,   76,   82,   88,   94],\n",
            "         [ 190,  212,  234,  256,  278],\n",
            "         [ 310,  348,  386,  424,  462]],\n",
            "\n",
            "        [[1510, 1564, 1618, 1672, 1726],\n",
            "         [1950, 2020, 2090, 2160, 2230],\n",
            "         [2390, 2476, 2562, 2648, 2734]]])\n"
          ]
        }
      ]
    }
  ]
}